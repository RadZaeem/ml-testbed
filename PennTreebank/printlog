5n6:~/raden/ml-testbed/PennTreebank> python braden_pbt.py 
/gs/hs0/tga-shinoda/17R70036/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
[1223 09:26:54 @logger.py:94] WRN Log directory train_log/braden_pbt exists! Please either backup/delete it, or use a new directory.
[1223 09:26:54 @logger.py:96] WRN If you're resuming from a previous run you can choose to keep it.
[1223 09:26:54 @logger.py:97] Select Action: k (keep) / b (backup) / d (delete) / n (new) / q (quit):
d
[1223 09:26:55 @logger.py:74] Argv: braden_pbt.py
[1223 09:26:55 @fs.py:89] WRN Env var $TENSORPACK_DATASET not set, using /home/9/17R70036/tensorpack_data for datasets.
[1223 09:26:56 @inference_runner.py:79] InferenceRunner will eval 184 iterations
[1223 09:26:56 @inference_runner.py:79] InferenceRunner will eval 206 iterations
[1223 09:26:56 @base.py:322] WRN You're calling new trainers with old trainer API!
[1223 09:26:56 @base.py:323] WRN Now it returns the old trainer for you, please switch to use new trainers soon!
[1223 09:26:56 @base.py:324] WRN See https://github.com/ppwwyyxx/tensorpack/issues/458 for more information.
[1223 09:26:56 @training.py:93] Building graph for training tower 0 ...
WARNING:tensorflow:From braden_pbt.py:92: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.

-> Input Rounding
Rounding:
Tensor("tower0/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)
[1223 09:26:57 @registry.py:121] fc input: [400, 300]

> Quantizing: <tf.Tensor 'tower0/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("tower0/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'tower0/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("tower0/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:57 @registry.py:129] fc output: [400, 10000]
[1223 09:26:58 @model_utils.py:49] Model Parameters: 
name                                                 shape             dim
---------------------------------------------------  ------------  -------
embedding:0                                          [10000, 300]  3000000
LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel:0  [600, 1200]    720000
LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias:0    [1200]           1200
fc/W:0                                               [300, 10000]  3000000
fc/b:0                                               [10000]         10000
Total #vars=5, #params=6731200, size=25.68MB
[1223 09:26:58 @base.py:143] Setup callbacks graph ...

==> Zeroing state

Rounding:
Tensor("RunOp/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:58 @predict.py:42] Building predictor tower 'InferenceTower' on device /gpu:0 ...

-> Input Rounding
Rounding:
Tensor("InferenceTower/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTower/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("InferenceTower/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTower/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("InferenceTower/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:58 @collection.py:139] Size of these collections were changed in InferenceTower: (tf.GraphKeys.QUEUE_RUNNERS: 1->2)
[1223 09:26:58 @collection.py:152] These collections were modified but restored in InferenceTower: (tf.GraphKeys.SUMMARIES: 8->13)

==> Zeroing state

Rounding:
Tensor("RunOp_1/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:58 @predict.py:42] Building predictor tower 'InferenceTowerTest' on device /gpu:0 ...

-> Input Rounding
Rounding:
Tensor("InferenceTowerTest/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTowerTest/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTowerTest/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:59 @collection.py:139] Size of these collections were changed in InferenceTowerTest: (tf.GraphKeys.QUEUE_RUNNERS: 2->3)
[1223 09:26:59 @collection.py:152] These collections were modified but restored in InferenceTowerTest: (tf.GraphKeys.SUMMARIES: 8->13)

==> Zeroing state

Rounding:
Tensor("RunOp_2/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:59 @summary.py:34] Maintain moving average summary of 2 tensors.
[1223 09:26:59 @base.py:148] Creating the session ...
2017-12-23 09:26:59.843301: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-12-23 09:27:00.460291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:85:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2017-12-23 09:27:00.460342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)
[1223 09:27:01 @base.py:152] Initializing the session ...
[1223 09:27:01 @base.py:159] Graph Finalized.


BASE at epoch 0
0.001
[1223 09:27:01 @param.py:144] After epoch 0, learning_rate will change to 0.00100000
[1223 09:27:02 @base.py:193] Start Epoch 1 ...
  0%|                                                                                                                           |0/2323[00:00<?,?it/s]
tfdbg: caught SIGINT; calling sys.exit(1).

17R70036@r8i5n6:~/raden/ml-testbed/PennTreebank> q
5n6:~/raden/ml-testbed/PennTreebank> python braden_pbt.py 
/gs/hs0/tga-shinoda/17R70036/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
[1223 09:26:54 @logger.py:94] WRN Log directory train_log/braden_pbt exists! Please either backup/delete it, or use a new directory.
[1223 09:26:54 @logger.py:96] WRN If you're resuming from a previous run you can choose to keep it.
[1223 09:26:54 @logger.py:97] Select Action: k (keep) / b (backup) / d (delete) / n (new) / q (quit):
d
[1223 09:26:55 @logger.py:74] Argv: braden_pbt.py
[1223 09:26:55 @fs.py:89] WRN Env var $TENSORPACK_DATASET not set, using /home/9/17R70036/tensorpack_data for datasets.
[1223 09:26:56 @inference_runner.py:79] InferenceRunner will eval 184 iterations
[1223 09:26:56 @inference_runner.py:79] InferenceRunner will eval 206 iterations
[1223 09:26:56 @base.py:322] WRN You're calling new trainers with old trainer API!
[1223 09:26:56 @base.py:323] WRN Now it returns the old trainer for you, please switch to use new trainers soon!
[1223 09:26:56 @base.py:324] WRN See https://github.com/ppwwyyxx/tensorpack/issues/458 for more information.
[1223 09:26:56 @training.py:93] Building graph for training tower 0 ...
WARNING:tensorflow:From braden_pbt.py:92: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.

-> Input Rounding
Rounding:
Tensor("tower0/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)
[1223 09:26:57 @registry.py:121] fc input: [400, 300]

> Quantizing: <tf.Tensor 'tower0/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("tower0/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'tower0/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("tower0/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:57 @registry.py:129] fc output: [400, 10000]
[1223 09:26:58 @model_utils.py:49] Model Parameters: 
name                                                 shape             dim
---------------------------------------------------  ------------  -------
embedding:0                                          [10000, 300]  3000000
LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel:0  [600, 1200]    720000
LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias:0    [1200]           1200
fc/W:0                                               [300, 10000]  3000000
fc/b:0                                               [10000]         10000
Total #vars=5, #params=6731200, size=25.68MB
[1223 09:26:58 @base.py:143] Setup callbacks graph ...

==> Zeroing state

Rounding:
Tensor("RunOp/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:58 @predict.py:42] Building predictor tower 'InferenceTower' on device /gpu:0 ...

-> Input Rounding
Rounding:
Tensor("InferenceTower/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTower/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("InferenceTower/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTower/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("InferenceTower/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:58 @collection.py:139] Size of these collections were changed in InferenceTower: (tf.GraphKeys.QUEUE_RUNNERS: 1->2)
[1223 09:26:58 @collection.py:152] These collections were modified but restored in InferenceTower: (tf.GraphKeys.SUMMARIES: 8->13)

==> Zeroing state

Rounding:
Tensor("RunOp_1/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:58 @predict.py:42] Building predictor tower 'InferenceTowerTest' on device /gpu:0 ...

-> Input Rounding
Rounding:
Tensor("InferenceTowerTest/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTowerTest/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTowerTest/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:59 @collection.py:139] Size of these collections were changed in InferenceTowerTest: (tf.GraphKeys.QUEUE_RUNNERS: 2->3)
[1223 09:26:59 @collection.py:152] These collections were modified but restored in InferenceTowerTest: (tf.GraphKeys.SUMMARIES: 8->13)

==> Zeroing state

Rounding:
Tensor("RunOp_2/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:59 @summary.py:34] Maintain moving average summary of 2 tensors.
[1223 09:26:59 @base.py:148] Creating the session ...
2017-12-23 09:26:59.843301: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-12-23 09:27:00.460291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:85:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2017-12-23 09:27:00.460342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)
[1223 09:27:01 @base.py:152] Initializing the session ...
[1223 09:27:01 @base.py:159] Graph Finalized.


BASE at epoch 0
0.001
[1223 09:27:01 @param.py:144] After epoch 0, learning_rate will change to 0.00100000
[1223 09:27:02 @base.py:193] Start Epoch 1 ...
  0%|                                                                                                                           |0/2323[00:00<?,?it/s]
tfdbg: caught SIGINT; calling sys.exit(1).

17R70036@r8i5n6:~/raden/ml-testbed/PennTreebank> q
5n6:~/raden/ml-testbed/PennTreebank> python braden_pbt.py 
/gs/hs0/tga-shinoda/17R70036/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
[1223 09:26:54 @logger.py:94] WRN Log directory train_log/braden_pbt exists! Please either backup/delete it, or use a new directory.
[1223 09:26:54 @logger.py:96] WRN If you're resuming from a previous run you can choose to keep it.
[1223 09:26:54 @logger.py:97] Select Action: k (keep) / b (backup) / d (delete) / n (new) / q (quit):
d
[1223 09:26:55 @logger.py:74] Argv: braden_pbt.py
[1223 09:26:55 @fs.py:89] WRN Env var $TENSORPACK_DATASET not set, using /home/9/17R70036/tensorpack_data for datasets.
[1223 09:26:56 @inference_runner.py:79] InferenceRunner will eval 184 iterations
[1223 09:26:56 @inference_runner.py:79] InferenceRunner will eval 206 iterations
[1223 09:26:56 @base.py:322] WRN You're calling new trainers with old trainer API!
[1223 09:26:56 @base.py:323] WRN Now it returns the old trainer for you, please switch to use new trainers soon!
[1223 09:26:56 @base.py:324] WRN See https://github.com/ppwwyyxx/tensorpack/issues/458 for more information.
[1223 09:26:56 @training.py:93] Building graph for training tower 0 ...
WARNING:tensorflow:From braden_pbt.py:92: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.

-> Input Rounding
Rounding:
Tensor("tower0/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)
[1223 09:26:57 @registry.py:121] fc input: [400, 300]

> Quantizing: <tf.Tensor 'tower0/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("tower0/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'tower0/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("tower0/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:57 @registry.py:129] fc output: [400, 10000]
[1223 09:26:58 @model_utils.py:49] Model Parameters: 
name                                                 shape             dim
---------------------------------------------------  ------------  -------
embedding:0                                          [10000, 300]  3000000
LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel:0  [600, 1200]    720000
LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias:0    [1200]           1200
fc/W:0                                               [300, 10000]  3000000
fc/b:0                                               [10000]         10000
Total #vars=5, #params=6731200, size=25.68MB
[1223 09:26:58 @base.py:143] Setup callbacks graph ...

==> Zeroing state

Rounding:
Tensor("RunOp/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:58 @predict.py:42] Building predictor tower 'InferenceTower' on device /gpu:0 ...

-> Input Rounding
Rounding:
Tensor("InferenceTower/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTower/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("InferenceTower/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTower/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("InferenceTower/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:58 @collection.py:139] Size of these collections were changed in InferenceTower: (tf.GraphKeys.QUEUE_RUNNERS: 1->2)
[1223 09:26:58 @collection.py:152] These collections were modified but restored in InferenceTower: (tf.GraphKeys.SUMMARIES: 8->13)

==> Zeroing state

Rounding:
Tensor("RunOp_1/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:58 @predict.py:42] Building predictor tower 'InferenceTowerTest' on device /gpu:0 ...

-> Input Rounding
Rounding:
Tensor("InferenceTowerTest/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTowerTest/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTowerTest/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:59 @collection.py:139] Size of these collections were changed in InferenceTowerTest: (tf.GraphKeys.QUEUE_RUNNERS: 2->3)
[1223 09:26:59 @collection.py:152] These collections were modified but restored in InferenceTowerTest: (tf.GraphKeys.SUMMARIES: 8->13)

==> Zeroing state

Rounding:
Tensor("RunOp_2/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:59 @summary.py:34] Maintain moving average summary of 2 tensors.
[1223 09:26:59 @base.py:148] Creating the session ...
2017-12-23 09:26:59.843301: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-12-23 09:27:00.460291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:85:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2017-12-23 09:27:00.460342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)
[1223 09:27:01 @base.py:152] Initializing the session ...
[1223 09:27:01 @base.py:159] Graph Finalized.


BASE at epoch 0
0.001
[1223 09:27:01 @param.py:144] After epoch 0, learning_rate will change to 0.00100000
[1223 09:27:02 @base.py:193] Start Epoch 1 ...
  0%|                                                                                                                           |0/2323[00:00<?,?it/s]
tfdbg: caught SIGINT; calling sys.exit(1).

17R70036@r8i5n6:~/raden/ml-testbed/PennTreebank> q
5n6:~/raden/ml-testbed/PennTreebank> python braden_pbt.py 
/gs/hs0/tga-shinoda/17R70036/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
[1223 09:26:54 @logger.py:94] WRN Log directory train_log/braden_pbt exists! Please either backup/delete it, or use a new directory.
[1223 09:26:54 @logger.py:96] WRN If you're resuming from a previous run you can choose to keep it.
[1223 09:26:54 @logger.py:97] Select Action: k (keep) / b (backup) / d (delete) / n (new) / q (quit):
d
[1223 09:26:55 @logger.py:74] Argv: braden_pbt.py
[1223 09:26:55 @fs.py:89] WRN Env var $TENSORPACK_DATASET not set, using /home/9/17R70036/tensorpack_data for datasets.
[1223 09:26:56 @inference_runner.py:79] InferenceRunner will eval 184 iterations
[1223 09:26:56 @inference_runner.py:79] InferenceRunner will eval 206 iterations
[1223 09:26:56 @base.py:322] WRN You're calling new trainers with old trainer API!
[1223 09:26:56 @base.py:323] WRN Now it returns the old trainer for you, please switch to use new trainers soon!
[1223 09:26:56 @base.py:324] WRN See https://github.com/ppwwyyxx/tensorpack/issues/458 for more information.
[1223 09:26:56 @training.py:93] Building graph for training tower 0 ...
WARNING:tensorflow:From braden_pbt.py:92: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.

-> Input Rounding
Rounding:
Tensor("tower0/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)
[1223 09:26:57 @registry.py:121] fc input: [400, 300]

> Quantizing: <tf.Tensor 'tower0/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("tower0/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'tower0/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("tower0/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:57 @registry.py:129] fc output: [400, 10000]
[1223 09:26:58 @model_utils.py:49] Model Parameters: 
name                                                 shape             dim
---------------------------------------------------  ------------  -------
embedding:0                                          [10000, 300]  3000000
LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel:0  [600, 1200]    720000
LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias:0    [1200]           1200
fc/W:0                                               [300, 10000]  3000000
fc/b:0                                               [10000]         10000
Total #vars=5, #params=6731200, size=25.68MB
[1223 09:26:58 @base.py:143] Setup callbacks graph ...

==> Zeroing state

Rounding:
Tensor("RunOp/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:58 @predict.py:42] Building predictor tower 'InferenceTower' on device /gpu:0 ...

-> Input Rounding
Rounding:
Tensor("InferenceTower/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTower/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("InferenceTower/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTower/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("InferenceTower/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:58 @collection.py:139] Size of these collections were changed in InferenceTower: (tf.GraphKeys.QUEUE_RUNNERS: 1->2)
[1223 09:26:58 @collection.py:152] These collections were modified but restored in InferenceTower: (tf.GraphKeys.SUMMARIES: 8->13)

==> Zeroing state

Rounding:
Tensor("RunOp_1/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:58 @predict.py:42] Building predictor tower 'InferenceTowerTest' on device /gpu:0 ...

-> Input Rounding
Rounding:
Tensor("InferenceTowerTest/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTowerTest/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTowerTest/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:59 @collection.py:139] Size of these collections were changed in InferenceTowerTest: (tf.GraphKeys.QUEUE_RUNNERS: 2->3)
[1223 09:26:59 @collection.py:152] These collections were modified but restored in InferenceTowerTest: (tf.GraphKeys.SUMMARIES: 8->13)

==> Zeroing state

Rounding:
Tensor("RunOp_2/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:59 @summary.py:34] Maintain moving average summary of 2 tensors.
[1223 09:26:59 @base.py:148] Creating the session ...
2017-12-23 09:26:59.843301: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-12-23 09:27:00.460291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:85:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2017-12-23 09:27:00.460342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)
[1223 09:27:01 @base.py:152] Initializing the session ...
[1223 09:27:01 @base.py:159] Graph Finalized.


BASE at epoch 0
0.001
[1223 09:27:01 @param.py:144] After epoch 0, learning_rate will change to 0.00100000
[1223 09:27:02 @base.py:193] Start Epoch 1 ...
  0%|                                                                                                                           |0/2323[00:00<?,?it/s]
tfdbg: caught SIGINT; calling sys.exit(1).

17R70036@r8i5n6:~/raden/ml-testbed/PennTreebank> q
5n6:~/raden/ml-testbed/PennTreebank> python braden_pbt.py 
/gs/hs0/tga-shinoda/17R70036/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
[1223 09:26:54 @logger.py:94] WRN Log directory train_log/braden_pbt exists! Please either backup/delete it, or use a new directory.
[1223 09:26:54 @logger.py:96] WRN If you're resuming from a previous run you can choose to keep it.
[1223 09:26:54 @logger.py:97] Select Action: k (keep) / b (backup) / d (delete) / n (new) / q (quit):
d
[1223 09:26:55 @logger.py:74] Argv: braden_pbt.py
[1223 09:26:55 @fs.py:89] WRN Env var $TENSORPACK_DATASET not set, using /home/9/17R70036/tensorpack_data for datasets.
[1223 09:26:56 @inference_runner.py:79] InferenceRunner will eval 184 iterations
[1223 09:26:56 @inference_runner.py:79] InferenceRunner will eval 206 iterations
[1223 09:26:56 @base.py:322] WRN You're calling new trainers with old trainer API!
[1223 09:26:56 @base.py:323] WRN Now it returns the old trainer for you, please switch to use new trainers soon!
[1223 09:26:56 @base.py:324] WRN See https://github.com/ppwwyyxx/tensorpack/issues/458 for more information.
[1223 09:26:56 @training.py:93] Building graph for training tower 0 ...
WARNING:tensorflow:From braden_pbt.py:92: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.

-> Input Rounding
Rounding:
Tensor("tower0/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)
[1223 09:26:57 @registry.py:121] fc input: [400, 300]

> Quantizing: <tf.Tensor 'tower0/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("tower0/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'tower0/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("tower0/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:57 @registry.py:129] fc output: [400, 10000]
[1223 09:26:58 @model_utils.py:49] Model Parameters: 
name                                                 shape             dim
---------------------------------------------------  ------------  -------
embedding:0                                          [10000, 300]  3000000
LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel:0  [600, 1200]    720000
LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias:0    [1200]           1200
fc/W:0                                               [300, 10000]  3000000
fc/b:0                                               [10000]         10000
Total #vars=5, #params=6731200, size=25.68MB
[1223 09:26:58 @base.py:143] Setup callbacks graph ...

==> Zeroing state

Rounding:
Tensor("RunOp/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:58 @predict.py:42] Building predictor tower 'InferenceTower' on device /gpu:0 ...

-> Input Rounding
Rounding:
Tensor("InferenceTower/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTower/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("InferenceTower/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTower/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("InferenceTower/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:58 @collection.py:139] Size of these collections were changed in InferenceTower: (tf.GraphKeys.QUEUE_RUNNERS: 1->2)
[1223 09:26:58 @collection.py:152] These collections were modified but restored in InferenceTower: (tf.GraphKeys.SUMMARIES: 8->13)

==> Zeroing state

Rounding:
Tensor("RunOp_1/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:58 @predict.py:42] Building predictor tower 'InferenceTowerTest' on device /gpu:0 ...

-> Input Rounding
Rounding:
Tensor("InferenceTowerTest/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTowerTest/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTowerTest/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:59 @collection.py:139] Size of these collections were changed in InferenceTowerTest: (tf.GraphKeys.QUEUE_RUNNERS: 2->3)
[1223 09:26:59 @collection.py:152] These collections were modified but restored in InferenceTowerTest: (tf.GraphKeys.SUMMARIES: 8->13)

==> Zeroing state

Rounding:
Tensor("RunOp_2/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:59 @summary.py:34] Maintain moving average summary of 2 tensors.
[1223 09:26:59 @base.py:148] Creating the session ...
2017-12-23 09:26:59.843301: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-12-23 09:27:00.460291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:85:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2017-12-23 09:27:00.460342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)
[1223 09:27:01 @base.py:152] Initializing the session ...
[1223 09:27:01 @base.py:159] Graph Finalized.


BASE at epoch 0
0.001
[1223 09:27:01 @param.py:144] After epoch 0, learning_rate will change to 0.00100000
[1223 09:27:02 @base.py:193] Start Epoch 1 ...
  0%|                                                                                                                           |0/2323[00:00<?,?it/s]
tfdbg: caught SIGINT; calling sys.exit(1).

17R70036@r8i5n6:~/raden/ml-testbed/PennTreebank> q
5n6:~/raden/ml-testbed/PennTreebank> python braden_pbt.py 
/gs/hs0/tga-shinoda/17R70036/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
[1223 09:26:54 @logger.py:94] WRN Log directory train_log/braden_pbt exists! Please either backup/delete it, or use a new directory.
[1223 09:26:54 @logger.py:96] WRN If you're resuming from a previous run you can choose to keep it.
[1223 09:26:54 @logger.py:97] Select Action: k (keep) / b (backup) / d (delete) / n (new) / q (quit):
d
[1223 09:26:55 @logger.py:74] Argv: braden_pbt.py
[1223 09:26:55 @fs.py:89] WRN Env var $TENSORPACK_DATASET not set, using /home/9/17R70036/tensorpack_data for datasets.
[1223 09:26:56 @inference_runner.py:79] InferenceRunner will eval 184 iterations
[1223 09:26:56 @inference_runner.py:79] InferenceRunner will eval 206 iterations
[1223 09:26:56 @base.py:322] WRN You're calling new trainers with old trainer API!
[1223 09:26:56 @base.py:323] WRN Now it returns the old trainer for you, please switch to use new trainers soon!
[1223 09:26:56 @base.py:324] WRN See https://github.com/ppwwyyxx/tensorpack/issues/458 for more information.
[1223 09:26:56 @training.py:93] Building graph for training tower 0 ...
WARNING:tensorflow:From braden_pbt.py:92: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.

-> Input Rounding
Rounding:
Tensor("tower0/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)
[1223 09:26:57 @registry.py:121] fc input: [400, 300]

> Quantizing: <tf.Tensor 'tower0/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("tower0/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'tower0/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("tower0/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:57 @registry.py:129] fc output: [400, 10000]
[1223 09:26:58 @model_utils.py:49] Model Parameters: 
name                                                 shape             dim
---------------------------------------------------  ------------  -------
embedding:0                                          [10000, 300]  3000000
LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel:0  [600, 1200]    720000
LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias:0    [1200]           1200
fc/W:0                                               [300, 10000]  3000000
fc/b:0                                               [10000]         10000
Total #vars=5, #params=6731200, size=25.68MB
[1223 09:26:58 @base.py:143] Setup callbacks graph ...

==> Zeroing state

Rounding:
Tensor("RunOp/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:58 @predict.py:42] Building predictor tower 'InferenceTower' on device /gpu:0 ...

-> Input Rounding
Rounding:
Tensor("InferenceTower/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTower/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("InferenceTower/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTower/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("InferenceTower/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:58 @collection.py:139] Size of these collections were changed in InferenceTower: (tf.GraphKeys.QUEUE_RUNNERS: 1->2)
[1223 09:26:58 @collection.py:152] These collections were modified but restored in InferenceTower: (tf.GraphKeys.SUMMARIES: 8->13)

==> Zeroing state

Rounding:
Tensor("RunOp_1/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:58 @predict.py:42] Building predictor tower 'InferenceTowerTest' on device /gpu:0 ...

-> Input Rounding
Rounding:
Tensor("InferenceTowerTest/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTowerTest/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTowerTest/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:59 @collection.py:139] Size of these collections were changed in InferenceTowerTest: (tf.GraphKeys.QUEUE_RUNNERS: 2->3)
[1223 09:26:59 @collection.py:152] These collections were modified but restored in InferenceTowerTest: (tf.GraphKeys.SUMMARIES: 8->13)

==> Zeroing state

Rounding:
Tensor("RunOp_2/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:59 @summary.py:34] Maintain moving average summary of 2 tensors.
[1223 09:26:59 @base.py:148] Creating the session ...
2017-12-23 09:26:59.843301: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-12-23 09:27:00.460291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:85:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2017-12-23 09:27:00.460342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)
[1223 09:27:01 @base.py:152] Initializing the session ...
[1223 09:27:01 @base.py:159] Graph Finalized.


BASE at epoch 0
0.001
[1223 09:27:01 @param.py:144] After epoch 0, learning_rate will change to 0.00100000
[1223 09:27:02 @base.py:193] Start Epoch 1 ...
  0%|                                                                                                                           |0/2323[00:00<?,?it/s]
tfdbg: caught SIGINT; calling sys.exit(1).

17R70036@r8i5n6:~/raden/ml-testbed/PennTreebank> q
5n6:~/raden/ml-testbed/PennTreebank> python braden_pbt.py 
/gs/hs0/tga-shinoda/17R70036/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
[1223 09:26:54 @logger.py:94] WRN Log directory train_log/braden_pbt exists! Please either backup/delete it, or use a new directory.
[1223 09:26:54 @logger.py:96] WRN If you're resuming from a previous run you can choose to keep it.
[1223 09:26:54 @logger.py:97] Select Action: k (keep) / b (backup) / d (delete) / n (new) / q (quit):
d
[1223 09:26:55 @logger.py:74] Argv: braden_pbt.py
[1223 09:26:55 @fs.py:89] WRN Env var $TENSORPACK_DATASET not set, using /home/9/17R70036/tensorpack_data for datasets.
[1223 09:26:56 @inference_runner.py:79] InferenceRunner will eval 184 iterations
[1223 09:26:56 @inference_runner.py:79] InferenceRunner will eval 206 iterations
[1223 09:26:56 @base.py:322] WRN You're calling new trainers with old trainer API!
[1223 09:26:56 @base.py:323] WRN Now it returns the old trainer for you, please switch to use new trainers soon!
[1223 09:26:56 @base.py:324] WRN See https://github.com/ppwwyyxx/tensorpack/issues/458 for more information.
[1223 09:26:56 @training.py:93] Building graph for training tower 0 ...
WARNING:tensorflow:From braden_pbt.py:92: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.

-> Input Rounding
Rounding:
Tensor("tower0/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)
[1223 09:26:57 @registry.py:121] fc input: [400, 300]

> Quantizing: <tf.Tensor 'tower0/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("tower0/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'tower0/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("tower0/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:57 @registry.py:129] fc output: [400, 10000]
[1223 09:26:58 @model_utils.py:49] Model Parameters: 
name                                                 shape             dim
---------------------------------------------------  ------------  -------
embedding:0                                          [10000, 300]  3000000
LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel:0  [600, 1200]    720000
LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias:0    [1200]           1200
fc/W:0                                               [300, 10000]  3000000
fc/b:0                                               [10000]         10000
Total #vars=5, #params=6731200, size=25.68MB
[1223 09:26:58 @base.py:143] Setup callbacks graph ...

==> Zeroing state

Rounding:
Tensor("RunOp/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:58 @predict.py:42] Building predictor tower 'InferenceTower' on device /gpu:0 ...

-> Input Rounding
Rounding:
Tensor("InferenceTower/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTower/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("InferenceTower/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTower/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("InferenceTower/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:58 @collection.py:139] Size of these collections were changed in InferenceTower: (tf.GraphKeys.QUEUE_RUNNERS: 1->2)
[1223 09:26:58 @collection.py:152] These collections were modified but restored in InferenceTower: (tf.GraphKeys.SUMMARIES: 8->13)

==> Zeroing state

Rounding:
Tensor("RunOp_1/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:58 @predict.py:42] Building predictor tower 'InferenceTowerTest' on device /gpu:0 ...

-> Input Rounding
Rounding:
Tensor("InferenceTowerTest/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTowerTest/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTowerTest/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:59 @collection.py:139] Size of these collections were changed in InferenceTowerTest: (tf.GraphKeys.QUEUE_RUNNERS: 2->3)
[1223 09:26:59 @collection.py:152] These collections were modified but restored in InferenceTowerTest: (tf.GraphKeys.SUMMARIES: 8->13)

==> Zeroing state

Rounding:
Tensor("RunOp_2/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:59 @summary.py:34] Maintain moving average summary of 2 tensors.
[1223 09:26:59 @base.py:148] Creating the session ...
2017-12-23 09:26:59.843301: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-12-23 09:27:00.460291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:85:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2017-12-23 09:27:00.460342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)
[1223 09:27:01 @base.py:152] Initializing the session ...
[1223 09:27:01 @base.py:159] Graph Finalized.


BASE at epoch 0
0.001
[1223 09:27:01 @param.py:144] After epoch 0, learning_rate will change to 0.00100000
[1223 09:27:02 @base.py:193] Start Epoch 1 ...
  0%|                                                                                                                           |0/2323[00:00<?,?it/s]
tfdbg: caught SIGINT; calling sys.exit(1).

17R70036@r8i5n6:~/raden/ml-testbed/PennTreebank> q
5n6:~/raden/ml-testbed/PennTreebank> python braden_pbt.py 
/gs/hs0/tga-shinoda/17R70036/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
[1223 09:26:54 @logger.py:94] WRN Log directory train_log/braden_pbt exists! Please either backup/delete it, or use a new directory.
[1223 09:26:54 @logger.py:96] WRN If you're resuming from a previous run you can choose to keep it.
[1223 09:26:54 @logger.py:97] Select Action: k (keep) / b (backup) / d (delete) / n (new) / q (quit):
d
[1223 09:26:55 @logger.py:74] Argv: braden_pbt.py
[1223 09:26:55 @fs.py:89] WRN Env var $TENSORPACK_DATASET not set, using /home/9/17R70036/tensorpack_data for datasets.
[1223 09:26:56 @inference_runner.py:79] InferenceRunner will eval 184 iterations
[1223 09:26:56 @inference_runner.py:79] InferenceRunner will eval 206 iterations
[1223 09:26:56 @base.py:322] WRN You're calling new trainers with old trainer API!
[1223 09:26:56 @base.py:323] WRN Now it returns the old trainer for you, please switch to use new trainers soon!
[1223 09:26:56 @base.py:324] WRN See https://github.com/ppwwyyxx/tensorpack/issues/458 for more information.
[1223 09:26:56 @training.py:93] Building graph for training tower 0 ...
WARNING:tensorflow:From braden_pbt.py:92: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.

-> Input Rounding
Rounding:
Tensor("tower0/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("tower0/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)
[1223 09:26:57 @registry.py:121] fc input: [400, 300]

> Quantizing: <tf.Tensor 'tower0/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("tower0/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'tower0/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("tower0/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:57 @registry.py:129] fc output: [400, 10000]
[1223 09:26:58 @model_utils.py:49] Model Parameters: 
name                                                 shape             dim
---------------------------------------------------  ------------  -------
embedding:0                                          [10000, 300]  3000000
LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel:0  [600, 1200]    720000
LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias:0    [1200]           1200
fc/W:0                                               [300, 10000]  3000000
fc/b:0                                               [10000]         10000
Total #vars=5, #params=6731200, size=25.68MB
[1223 09:26:58 @base.py:143] Setup callbacks graph ...

==> Zeroing state

Rounding:
Tensor("RunOp/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:58 @predict.py:42] Building predictor tower 'InferenceTower' on device /gpu:0 ...

-> Input Rounding
Rounding:
Tensor("InferenceTower/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTower/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTower/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("InferenceTower/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTower/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("InferenceTower/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:58 @collection.py:139] Size of these collections were changed in InferenceTower: (tf.GraphKeys.QUEUE_RUNNERS: 1->2)
[1223 09:26:58 @collection.py:152] These collections were modified but restored in InferenceTower: (tf.GraphKeys.SUMMARIES: 8->13)

==> Zeroing state

Rounding:
Tensor("RunOp_1/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:58 @predict.py:42] Building predictor tower 'InferenceTowerTest' on device /gpu:0 ...

-> Input Rounding
Rounding:
Tensor("InferenceTowerTest/Relu:0", shape=(20, 20, 300), dtype=float32, device=/device:GPU:0)


The STATE:
(LSTMStateTuple(c=<tf.Variable 'c0:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h0:0' shape=(20, 300) dtype=float32_ref>), LSTMStateTuple(c=<tf.Variable 'c1:0' shape=(20, 300) dtype=float32_ref>, h=<tf.Variable 'h1:0' shape=(20, 300) dtype=float32_ref>))

Before quantize name: LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/kernel

> Quantizing: <tf.Tensor 'InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/Tanh:0' shape=(600, 1200) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/BitLSTMCell/add:0", shape=(600, 1200), dtype=float32, device=/device:GPU:0)

NOT Quantizing:LSTM/rnn/multi_rnn_cell/cell_0/BitLSTMCell/bias

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_1/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_2/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_3/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_4/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_5/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_6/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_7/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_8/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_9/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_10/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_11/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_12/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_13/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_14/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_15/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_16/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_17/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_18/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

Rounding new_h
Rounding:
Tensor("InferenceTowerTest/LSTM/rnn/rnn/multi_rnn_cell/cell_0_19/BitLSTMCell/mul_2:0", shape=(20, 300), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTowerTest/fc/Tanh:0' shape=(300, 10000) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/fc/add:0", shape=(300, 10000), dtype=float32, device=/device:GPU:0)

> Quantizing: <tf.Tensor 'InferenceTowerTest/fc/Tanh_1:0' shape=(10000,) dtype=float32>
Rounding:
Tensor("InferenceTowerTest/fc/add_1:0", shape=(10000,), dtype=float32, device=/device:GPU:0)
[1223 09:26:59 @collection.py:139] Size of these collections were changed in InferenceTowerTest: (tf.GraphKeys.QUEUE_RUNNERS: 2->3)
[1223 09:26:59 @collection.py:152] These collections were modified but restored in InferenceTowerTest: (tf.GraphKeys.SUMMARIES: 8->13)

==> Zeroing state

Rounding:
Tensor("RunOp_2/Sigmoid:0", shape=(20, 300), dtype=float32)

Resetting state

[1223 09:26:59 @summary.py:34] Maintain moving average summary of 2 tensors.
[1223 09:26:59 @base.py:148] Creating the session ...
2017-12-23 09:26:59.843301: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-12-23 09:27:00.460291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:85:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2017-12-23 09:27:00.460342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)
[1223 09:27:01 @base.py:152] Initializing the session ...
[1223 09:27:01 @base.py:159] Graph Finalized.


BASE at epoch 0
0.001
[1223 09:27:01 @param.py:144] After epoch 0, learning_rate will change to 0.00100000
[1223 09:27:02 @base.py:193] Start Epoch 1 ...
  0%|                                                                                                                           |0/2323[00:00<?,?it/s]
tfdbg: caught SIGINT; calling sys.exit(1).

17R70036@r8i5n6:~/raden/ml-testbed/PennTreebank> q

